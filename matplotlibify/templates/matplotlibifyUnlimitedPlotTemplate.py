"""
@author: tharrison
This script was automatically generated by Tim Harrison's matplotlibify
script. The template use {{}} to denote variables to be automatically replaced.
This script was generated on {{DATE}}
"""
import logging
import scipy
import pandas
import itertools
import matplotlib.pyplot as plt
import matplotlib.dates as mdate
import os
from scipy import inf
logger=logging.getLogger("ExperimentEagle.logFilePlotEngine")


#######
#Parameters for plotting
#######

legendReplacements = {{lfp1.legendReplacements}}#dictionary
xAxisLabel = {{lfp1.xAxisLabel}}
yAxisLabel = {{lfp1.yAxisLabel}}
setXLimitsBool = {{lfp1.setXLimitsBool}}
setYLimitsBool = {{lfp1.setYLimitsBool}}
xlimits = {{lfp1.xlimits}}
ylimits = {{lfp1.ylimits}}

plotErrorBars = {{lfp1.plotErrorBars}}
plotFormatString = {{lfp1.plotFormatString}}
interpretAsTimeAxis = {{lfp1.interpretAsTimeAxis}}
logScaleX1 = {{lfp1.xLogScale}}
logScaleY1 = {{lfp1.yLogScale}}

isFittedBool = {{lfp1.isFitted}}
fitFunctionName = {{lfp1.fitFunction}}
fittedParameters = {{lfp1.fitValues}}
useFitFile = {{lfp1.useFitFile}}
fitFile = {{lfp1.fitFile}}
{{lfp1.fitFunctionSource}}

matplotlibifyMode = {{matplotlibifyMode}}
showWaterMark =  {{showWaterMark}}
hardCodeLegendBool = {{hardCodeLegendBool}}
hardCodeLegendString = {{hardCodeLegendString}}
dualPlotMode = {{dualPlotMode}}

class LogFilePlotEngine(object):
    """just analyses and aggregates data in eagle log files. subset of the code
    in LogFilePlot"""
    from scipy import inf
    mode=None
    
    logFile = None
    xAxis = None
    yAxis = None
    aggregateAxis = None
    series = None

    filterYs = None
    filterMinYs = None
    filterMaxYs = None
    
    filterXs = None
    filterMinXs = None
    filterMaxXs = None
    
    filterNaN = None
    
    filterSpecific = None
    filterSpecificString = None
    
    #plot properties
    scaleXBool = {{lfp1.scaleXBool}}
    scaleYBool = {{lfp1.scaleYBool}}
    scaleX =     {{lfp1.scaleX}}
    scaleY =     {{lfp1.scaleY}}
    offsetX =    {{lfp1.offsetX}}
    offsetY =    {{lfp1.offsetY}}
    
    def __init__(self, **kwargs):
        """constructor creates attributes from kwargs """
        super(LogFilePlotEngine,self).__init__()
        for key in kwargs:
            setattr(self, key, kwargs[key])
            
    def parseSeries(self):
        """series is a column seperated string of all columns in log file 
        to be treated as a seperate series. If there are multiple values
        each unique combination is a new series"""
        if self.series=="":
            return []
        else:
            return self.series.split(",")
    
    def getData(self):
        """using pandas, this function aggregates the data and groups by
        each series combination. Returns the aggregated data at which point 
        we can now see what we need to plot etc.

        All filters are performed after getting the dataframe but before returning
        the aggregate frame.
        """
        try:
            self.dataframe = pandas.read_csv(self.logFile, index_col="datetime", parse_dates = True)
        except ValueError as e:
            logger.error("No datetime column. Is this a valid Eagle log file? I will try without index")
            self.dataframe = pandas.read_csv(self.logFile, parse_dates = True)  
        self.filterData()
        seriesList = self.parseSeries()
        if self.mode == "X Variable - Measured Y":
            #The last column we aggregate over is the x axis. y axis gets mean and stdev per aggregation
            return self.dataframe.groupby(seriesList+[self.xAxis], as_index=False).aggregate({self.yAxis:["mean","std"]})
        elif self.mode == "X Measured - Y Measured":
            #here the x axis needs to be aggregated to mean and stdev as well as the y axis. aggregate axis defines the last axis we aggregate over
            #classic example here is a N vs T plot where aggregate axis is evaporation time. series would be for evaporation at different MT gradients
            return self.dataframe.groupby(seriesList+[self.aggregateAxis], as_index=False).aggregate({self.xAxis:["mean","std"],self.yAxis:["mean","std"]})
        elif self.mode == "XY Scatter":
            #here we don't care if x is a variable or measured. We just plot every x y point as a scatter point. no error bars.
            #here the raw data frame contains everything we need in the correct format!            
            return self.dataframe[seriesList+[self.xAxis,self.yAxis]]
        
    def humanSeriesName(self, seriesTuple):
        """returns the name for a given series Tuple"""
        name=""
        c=0
        for seriesName in self.seriesList:
            name+=seriesName+"="+str(seriesTuple[c])+" "
            c+=1
        name = name.strip(" ")
        return name
        
    def filterData(self):
        """filtering before aggregating the data for plots """
        if self.filterYs:
            self.performFilterYS()
        if self.filterXs:
            self.performFilterXS()
        if self.filterNaN:
            self.performFilterNaN()
        if self.filterSpecific:
            self.performFilterSpecific()
        
    def performFilterYS(self):
        """ remove y values above or below set bounds"""
        logger.debug("filtering y data before aggregating and plotting")
        logger.debug("dataframe was %s rows" % (len(self.dataframe)))
        self.dataframe = self.dataframe[(self.dataframe[self.yAxis]>self.filterMinYs) &(self.dataframe[self.yAxis]<self.filterMaxYs)]
        logger.debug("dataframe now %s rows" % (len(self.dataframe)))
        
    def performFilterXS(self):
        """remove x data above or below set bounds """
        logger.debug("filtering x data before aggregating and plotting")
        logger.debug("dataframe was %s rows" % (len(self.dataframe)))
        self.dataframe = self.dataframe[(self.dataframe[self.xAxis]>self.filterMinXs) &(self.dataframe[self.xAxis]<self.filterMaxXs)]
        logger.debug("dataframe now %s rows" % (len(self.dataframe)))
        
    def performFilterNaN(self):
        """removes NaN and replaces with zero """
        logger.debug("filtering NaN--> 0 in place")
        self.dataframe.fillna(value=0.0, inplace=True)

    def performFilterSpecific(self):
        """specific filter string is a comma separated list of filters. Supported filters are:
        ==, >, <"""
        filterStrings = self.filterSpecificString.split(",")
        for query in filterStrings:
            query = query.strip()
            if "==" in query:
                columnName, value = query.split("==")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]==value]
            elif ">" in query:
                columnName, value = query.split(">")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]>value]
            elif "<" in query:
                columnName, value = query.split("<")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]<value]
            else:
                logger.error("unrecognised operator for query")
                
    def getUniqueSeries(self, aggregatedDataFrame):
        """ given a aggregated data frame, this returns the list of all series
        names that are contained in the logFile."""
        self.seriesList = self.parseSeries()
        uniqueValues = [aggregatedDataFrame[seriesName].unique() for seriesName in self.seriesList] # [array(uniquevaluesseries1), array(uniquevaluesseries2),...]
        uniqueSeriesValues = list(itertools.product(*uniqueValues))#TODO at this point we should filter to only unique series combinations that actually have data
        #uniqueSeriesValuesWithData = []
        return uniqueSeriesValues
        
    def getRelevantData(self,aggregatedDataFrame,uniqueSeriesValueTuple):
        """given a uniqueSeriesValueTuple (e.g. (35, 0.002, 1) for (gradient, TOFtime, dummyVar)
        we return the aggregated data frame filtered to the relevant series.
        Returns None if there is no data in the relevant data frame this allows user to catch a non existing legend series        
        """
        relevantDataFrame = aggregatedDataFrame
        for columnName, value in zip(self.seriesList,uniqueSeriesValueTuple):
            logger.debug( "columnName, value = %s, %s" % (columnName, value) )
            logger.debug( "relevantDataFrame[relevantDataFrame[%s]==%s]" % (columnName, value) )
            relevantDataFrame = relevantDataFrame[relevantDataFrame[columnName]==value]
        logger.debug("relevantDataFrame = \n %s" % relevantDataFrame)
        if len(relevantDataFrame)==0:
            return None
        return relevantDataFrame        

    def setFittingData(self):
        """gets a list of all valid series aggregated
        then iterates through and sends them to fitting module"""
        logger.info("beginning set Fitting Data func")
        aggregatedDataFrame = self.getData()
        uniqueSeriesValueTuples = self.getUniqueSeries(aggregatedDataFrame)
        logger.warning("uniqueSeriesValuesTuples=%s", uniqueSeriesValueTuples)
        validNames = []#can change when user presses refresh
        for uniqueSeriesValueTuple in uniqueSeriesValueTuples:#TODO ADD SORTED STATEMENT  
            relevantDataFrame=self.getRelevantData(aggregatedDataFrame,uniqueSeriesValueTuple)
            if relevantDataFrame is None:#skip non existing legend series
                continue
            xs = relevantDataFrame[self.xAxis].values
            if self.mode == "XY Scatter":
                ys = relevantDataFrame[self.yAxis].values
            else:
                ys = relevantDataFrame[self.yAxis,"mean"].values
            humanName = self.humanSeriesName(uniqueSeriesValueTuple)
            if humanName == "":
                humanName="data"
            self.logFilePlotFitterReference.setFitData(humanName,xs,ys)
            validNames.append(humanName) 
        self.logFilePlotFitterReference.cleanValidNames(validNames)#removes unecessary elements from datasets dict
        self.logFilePlotFitterReference.setValidNames()#resets name choices to only be remaining valid keys of datasets dict

##############################################
#CLASS LOGFILEPLOT ENGINE COMPLETE, NOW MATPLOTLIB PLOTTING
##############################################

engine1 = LogFilePlotEngine(mode={{lfp1.mode}},  logFile = {{lfp1.logFile}},
                            xAxis = {{lfp1.xAxis}},yAxis = {{lfp1.yAxis}},aggregateAxis = {{lfp1.aggregateAxis}},
                            series = {{lfp1.series}},filterYs = {{lfp1.fiterYs}},filterMinYs = {{lfp1.filterMinYs}},filterMaxYs = {{lfp1.filterMaxYs}},
                            filterXs = {{lfp1.filterXs}},filterMinXs = {{lfp1.filterMinXs}},filterMaxXs = {{lfp1.filterMaxXs}},filterNaN = {{lfp1.filterNaN}},filterSpecific = {{lfp1.filterSpecific}},
                            filterSpecificString = {{lfp1.filterSpecificString}})

engine2 = LogFilePlotEngine(mode={{lfp2.mode}},  logFile = {{lfp2.logFile}},
                            xAxis = {{lfp2.xAxis}},yAxis = {{lfp2.yAxis}},aggregateAxis = {{lfp2.aggregateAxis}},
                            series = {{lfp2.series}},filterYs = {{lfp2.fiterYs}},filterMinYs = {{lfp2.filterMinYs}},filterMaxYs = {{lfp2.filterMaxYs}},
                            filterXs = {{lfp2.filterXs}},filterMinXs = {{lfp2.filterMinXs}},filterMaxXs = {{lfp2.filterMaxXs}},filterNaN = {{lfp2.filterNaN}},filterSpecific = {{lfp2.filterSpecific}},
                            filterSpecificString = {{lfp2.filterSpecificString}})


engines = [engine1,engine2]
numberOfPlots = len(engines)

plt.style.use(os.path.join("\\\\ursa","AQOGroupFolder","Experiment Humphry","Experiment Control And Software","LogFilePlots","matplotlibify","defaultThesis.mplstyle"))
if dualPlotMode=='sharedXY':
    fig, ax = plt.subplots()
    axes = [ax for i in range(0, len(engines))]
elif (dualPlotMode=='stacked' and (engine1.xAxis == engine2.xAxis)) or dualPlotMode=='stackedX':
    fig, axes = plt.subplots(nrows=len(engines), ncols=1, sharex=True)
elif (dualPlotMode=='stacked' and (engine1.yAxis == engine2.yAxis)) or dualPlotMode=='stackedY':
    fig, axes = plt.subplots(nrows=1, ncols=len(engines), sharey=True)
elif dualPlotMode=='stacked':
    fig, axes = plt.subplots(nrows=len(engines), ncols=1)
else:
    fig, ax = plt.subplots()
    axes = [ax for i in range(0, len(engines))]

cycle = axes[0]._get_lines.prop_cycler

def plotFunction(engine, axis):
    aggregatedDataFrame = engine.getData()
    uniqueSeries = engine.getUniqueSeries(aggregatedDataFrame)
    
    if not engine.scaleXBool:
        engine.scaleX=1.
        engine.offsetX=0.
        
    if not engine.scaleYBool:
        engine.scaleY=1.
        engine.offsetY=0.

    plots = []
    legendNames = []
    for series in uniqueSeries:
        relevantDataFrame = engine.getRelevantData(aggregatedDataFrame,series )
        if relevantDataFrame is None:#skip non existing legend series
            continue
        #get appropriate y line (mean) data    
        if engine.mode=="X Measured - Y Measured":
            xs = relevantDataFrame[engine.xAxis, "mean"].values
            ys = relevantDataFrame[engine.yAxis,"mean"].values
            sigmasX = relevantDataFrame[engine.xAxis,"std"].values
            sigmasY = relevantDataFrame[engine.yAxis,"std"].values
            xs = engine.scaleX*xs+engine.offsetX #has no effect if scaleXBool is False
            ys = engine.scaleY*ys+engine.offsetY #has no effect if scaleXBool is False
            sigmasX = engine.scaleX*sigmasX+engine.offsetX#has no effect if scaleXBool is False
            sigmasY = engine.scaleY*sigmasY+engine.offsetY#has no effect if scaleXBool is False
            if interpretAsTimeAxis:
                xs = mdate.epoch2num(xs)
            plot = axis.plot(xs,ys, plotFormatString, color=next(cycle)['color'])[0]
            if plotErrorBars:
                axis.errorbar(xs, ys,yerr=sigmasY,ls='none',alpha=0.75,color=plot.get_color())
        elif engine1.mode=="X Variable - Measured Y":
            xs = relevantDataFrame[engine.xAxis].values
            ys = relevantDataFrame[engine.yAxis,"mean"].values
            sigmasY = relevantDataFrame[engine.yAxis,"std"].values
            xs = engine.scaleX*xs+engine.offsetX #has no effect if scaleXBool is False
            ys = engine.scaleY*ys+engine.offsetY #has no effect if scaleXBool is False
            sigmasY = engine.scaleY*sigmasY+engine.offsetY#has no effect if scaleXBool is False
            if interpretAsTimeAxis:
                xs = mdate.epoch2num(xs)
            plot = axis.plot(xs,ys, plotFormatString, color=next(cycle)['color'])[0]
            if plotErrorBars:
                axis.errorbar(xs, ys,yerr=sigmasY,ls='none',alpha=0.75,color=plot.get_color())
        elif engine1.mode == "XY Scatter":
            xs = relevantDataFrame[engine.xAxis].values
            ys = relevantDataFrame[engine.yAxis].values
            xs = engine.scaleX*xs+engine.offsetX #has no effect if scaleXBool is False
            ys = engine.scaleY*ys+engine.offsetY #has no effect if scaleXBool is False
            if interpretAsTimeAxis:
                xs = mdate.epoch2num(xs)
            plot = axis.plot(xs,ys, plotFormatString, color=next(cycle)['color'])[0]
        else:
            logger.error("unrecognised mode")
        plots.append(plot)
        humanName = engine.humanSeriesName(series)
        for old, new in legendReplacements.iteritems():
            humanName = humanName.replace(old,new)
        if humanName == "":
            humanName = yAxisLabel
        else:
            humanName = yAxisLabel + ": "+humanName
        legendNames.append(humanName)
    return (plots,legendNames)
        
axes[-1].set_xlabel(xAxisLabel)
axes[-1].set_ylabel(yAxisLabel)

for (engine, axis) in zip(engines, axes):
    plots, legendNames = plotFunction(engine,axis)
    
if hardCodeLegendBool:
    legendNames = hardCodeLegendString.split(",")
    axes[0].legend(plots,legendNames)
elif len(legendNames) >1:# dont legend plots unless  there are more than 2
    axis.legend(plots,legendNames)

if logScaleX1:
    axis.set_xscale("log", nonposx="clip")
if logScaleY1:
    axis.set_yscale("log", nonposx="clip")
if setXLimitsBool:
    axis.set_xlim(xlimits)
if setYLimitsBool:
    axis.set_ylim(ylimits)
if interpretAsTimeAxis:
    axis.xaxis_date()

logFolder,tail = os.path.split(engine1.logFile)
logNameString = tail.replace(".csv","")
watermark = 'Automatic Eagle Plot for OneNote\n%s' % (logNameString)# DO NOT REMOVE!!!!
if showWaterMark:
    fig.text(0.15, 0.15,watermark ,
             fontsize=12, color='red',
             ha='left', va='bottom', alpha=0.5)

plt.show()    

try:
    print __file__.replace("\\","/")
except NameError:
    pass