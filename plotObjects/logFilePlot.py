# -*- coding: utf-8 -*-
"""
Created on Sat May 23 11:35:11 2015

@author: tharrison

Plots nice scatter/errorbar plots of the log files generated by experiment eagle
Back bone of data aggregation is python pandas module
"""

import chaco.api as chaco
import chaco.tools.api as tools
import traits.api as traits
import traitsui.api as traitsui
import logging
import os
import csv
import json
import scipy
import logFilePlotFitter
import keyBindingsTool
import scatterSelectorTool
import time
import pandas
import numpy as np
import datetime
import itertools
import legendHighlighter
import oneNotePython.logLibrarianOneNote
import shutil
import traceback
import enable.api as enable


from enable.api import  ComponentEditor
from chaco.scales.api import CalendarScaleSystem
from chaco.scales_tick_generator import ScalesTickGenerator
#import traitsui.message

logger=logging.getLogger("LogFilePlots.logFilePlot")
#oneNote Support
try:
    import oneNotePython.eagleLogsOneNote
    ONENOTE_ENABLED=True
    ONENOTE_NotebookName = "Humphry's Notebook"
    ONENOTE_SectionName = "Eagle Logs"
except Exception as e:
    logger.error("failed to import oneNotePython. error message: %s" % e.message)
    ONENOTE_ENABLED=False

RGBCONTRASTCOLORS = [(1.0, 0.0, 0.0), (0.8941176470588236, 0.8941176470588236, 0.0), (0.0, 1.0, 0.0), (0.0, 1.0, 1.0), (0.6901960784313725, 0.6901960784313725, 1.0), (1.0, 0.0, 1.0), (0.8941176470588236, 0.8941176470588236, 0.8941176470588236), (0.6901960784313725, 0.0, 0.0), (0.7294117647058823, 0.7294117647058823, 0.0), (0.0, 0.6901960784313725, 0.0), (0.0, 0.6901960784313725, 0.6901960784313725), (0.5176470588235295, 0.5176470588235295, 1.0), (0.6901960784313725, 0.0, 0.6901960784313725), (0.7294117647058823, 0.7294117647058823, 0.7294117647058823), (0.5294117647058824, 0.0, 0.0), (0.5294117647058824, 0.5294117647058824, 0.0), (0.0, 0.5294117647058824, 0.0), (0.0, 0.5294117647058824, 0.5294117647058824), (0.28627450980392155, 0.28627450980392155, 1.0), (0.5294117647058824, 0.0, 0.5294117647058824), (0.5294117647058824, 0.5294117647058824, 0.5294117647058824), (0.3333333333333333, 0.0, 0.0), (0.32941176470588235, 0.32941176470588235, 0.0), (0.0, 0.3333333333333333, 0.0), (0.0, 0.3333333333333333, 0.3333333333333333), (0.0, 0.0, 1.0), (0.3333333333333333, 0.0, 0.3333333333333333), (0.32941176470588235, 0.32941176470588235, 0.32941176470588235)]

assert os.path.exists(r'G:\Experiment Humphry\Data\eagleLogs\default.csv')

class LogFilePlot(traits.HasTraits):
    """analyse and plot the log files created by Eagle """
    mode=traits.Enum("X Variable - Measured Y", "X Measured - Y Measured", "XY Scatter")
    logFilePlotBool = traits.Bool(False)
    fitLogFileBool = traits.Bool(False)
    autoFitWithRefresh = traits.Bool(False)
    softRefresh = traits.Bool(False)
    errorBarMode = traits.Enum("std dev", "std err")
    groupSimilarValues = traits.Bool(True)
    groupValuesAccuracy = traits.Int(10)
    
    refreshButton = traits.Button("Refresh")
    savePlotButton = traits.Button("Save Plot")
    librarianButton = traits.Button("Librarian")
    deleteLogButton = traits.Button("Delete Log")
    deleteSelectedButton = traits.Button("Delete Sel")
    settingsAvailable = traits.Bool(False)
    loadSettingsButton = traits.Button("Load Settings")
    saveSettingsButton = traits.Button("Save Settings")
    
    logFile = traits.File(r'N:\Data\eagleLogs\default.csv')
    # logFile = traits.File(r'G:\Experiment Humphry\Data\eagleLogs\default.csv')
    xAxis = traits.Enum(values="masterList")
    yAxis = traits.Enum(values="masterList")
    aggregateAxis = traits.Enum(values="masterList")
    masterList = traits.List
    series = traits.String("")
    seriesEdit  = traits.Button("choose series")
    seriesSelectedColumns = traits.List(traits.String)
    
    xLogScale = traits.Bool(False)
    yLogScale = traits.Bool(False)
    interpretAsTimeAxis = traits.Bool(False, desc="if x axis is epoch seconds this will transform it into a pretty time scale axis")
    filterYs = traits.Bool(False)
    filterMinYs = traits.Float(-scipy.inf)
    filterMaxYs = traits.Float(scipy.inf)
    
    filterXs = traits.Bool(False)
    filterMinXs = traits.Float(-scipy.inf)
    filterMaxXs = traits.Float(scipy.inf)
    
    filterNaN = traits.Bool(True, desc="If true all NaN values are replaced with zero")    
    
    filterSpecific = traits.Bool(False, desc = "Filter by selected variable")
    filterSpecificString = traits.String("", desc="Filters pandas dataframe with an arbitrary complex query.")
    filterVariableSelector = traits.Enum(values="masterList") 
    
    index_mapper_class = chaco.LinearMapper
    value_mapper_class = chaco.LinearMapper

    logFilePlotsBool = traits.Bool(False, desc="only set to true if a logfileplots gui is instantiating this log file plot")    
    logFilePlotsTabName = traits.String("Log File Plot", desc="name used in tab when logFilePlots GUI is being used" )
    logFilePlotsReference = None#kept as None unless logFilePlotsBool is True
    eagleReference = None
    logFilePlotFitterReference = traits.Instance(logFilePlotFitter.LogFilePlotFitter)

    autoRefreshObject = None # set to none when there is no autorefresh set up , or to the autoRefreshDialog object when there is. dialog object has all necessary info for alerts etc.

    oldLegendPosition = None
    keyBindingsDictionary = {} #defined in __init___                                
                                     
    filterGroup = traitsui.VGroup(
                                traitsui.HGroup(traitsui.Item("filterYs", label="filter Y data?"),
                                                traitsui.Item("filterMinYs", label="minimum", visible_when="filterYs"),
                                                traitsui.Item("filterMaxYs", label="maximum", visible_when="filterYs")),
                                traitsui.HGroup(traitsui.Item("filterXs", label="filter X data?"),
                                                traitsui.Item("filterMinXs", label="minimum", visible_when="filterXs"),
                                                traitsui.Item("filterMaxXs", label="maximum", visible_when="filterXs")),
                                traitsui.HGroup(traitsui.Item("filterNaN", label="filter NaNs?")),
                                traitsui.HGroup(traitsui.Item("filterSpecific", label="specific filter?"),
                                                traitsui.Item("filterVariableSelector", label="variable:", visible_when="filterSpecific", width=-100),
                                                traitsui.Item("filterSpecificString", label="filter", visible_when="filterSpecific")),
                                label="Filters", show_border=True                                
                                )
    
    fileGroup = traitsui.VGroup(
                                traitsui.Item("logFile", label="log file"),
                                traitsui.HGroup(traitsui.Item("xAxis", label="x axis"),traitsui.Item("xLogScale", label="x log scale?" ),traitsui.Item("interpretAsTimeAxis", label="time axis?")),
                                traitsui.HGroup(traitsui.Item("yAxis", label="y axis"),traitsui.Item("yLogScale", label="y log scale?" )),
                                traitsui.HGroup(traitsui.Item("aggregateAxis", label="aggregate", visible_when = '(mode=="X Measured - Y Measured")')),
                                traitsui.HGroup(traitsui.Item("series",label="series", style="readonly"),traitsui.Item("seriesEdit", show_label=False)),
                                traitsui.HGroup(traitsui.Item("logFilePlotsTabName", label="name"), visible_when = "logFilePlotsBool" ),
                                label="Log File", show_border=True
                                )
                                
    optionsGroup = traitsui.VGroup(
                                traitsui.VGroup(
                                    traitsui.HGroup(
                                        traitsui.Item("mode", label="plot mode"),
                                        traitsui.Item("errorBarMode",label="error bar",visible_when='mode!="XY Scatter"'),
                                        traitsui.Item("logFilePlotBool", label="Show Plot?"),
                                        traitsui.Item("groupSimilarValues", visible_when='mode=="X Variable - Measured Y"'),
                                        traitsui.Item("groupValuesAccuracy", visible_when='mode=="X Variable - Measured Y"')
                                    ),
                                    traitsui.HGroup(
                                        traitsui.Item("fitLogFileBool", label="Fit?"),                                    
                                        traitsui.Item("autoFitWithRefresh", label="Fit with Refresh?"),
                                        traitsui.Item("softRefresh", label="soft refresh?"),
                                        traitsui.Item("loadSettingsButton", show_label=False, enabled_when='settingsAvailable'),
                                        traitsui.Item("saveSettingsButton", show_label=False)
                                    )
                                ),
                                traitsui.HGroup(
                                    traitsui.Item("refreshButton", show_label=False), 
                                    traitsui.Item("savePlotButton", show_label=False),
                                    traitsui.Item("librarianButton", show_label=False),
                                    traitsui.Item("deleteLogButton", show_label=False),
                                    traitsui.Item("deleteSelectedButton", show_label=False, enabled_when='mode=="XY Scatter"')                   
                                    ),
                                label="Options", show_border=True
                                ),
                                                 
    settingsGroup = traitsui.VGroup(
                        traitsui.HGroup(traitsui.VGroup(optionsGroup,filterGroup),fileGroup,)
                        )
                                                          
    
    plotGroup = traitsui.Group(
                    traitsui.Item('container', editor=ComponentEditor(), show_label=False), 
                        )

    fitterGroup = traitsui.Group(traitsui.Item('logFilePlotFitterReference',style="custom",editor=traitsui.InstanceEditor(),label="Fits", show_label=False ), springy=True,visible_when="fitLogFileBool")
    
    mainGroup = traitsui.Group(settingsGroup, plotGroup)    
    traits_view = traitsui.View(traitsui.HSplit(mainGroup,fitterGroup), resizable=True)
    
    def __init__(self, **traitsDict):
        """This class wraps up a chaco line plot and chaco error bar plots so 
        that it can easily be used for plotting the outputs of experiment eagle
        log files.
        
        When log plot bool is changed or plot is refreshed the routine is:
        --> clear all current plots
        --> pull new data from logfile using pandas read_csv
        -->
        """
        super(LogFilePlot, self).__init__(**traitsDict)
        logger.debug("log file plot initialising")
        self.plots={}
        self.errorPlots={}
        self.currentlyDefinedSeries = []
        self.fitPlot = None
        self.masterList = self._getMasterList()
        self.logFilePlotFitterReference=logFilePlotFitter.LogFilePlotFitter()
        self.logFilePlotFitterReference.logFilePlotReference = self#so it can no the logFileName for saving fits to the correct folder
        #2016 08 18 - now an attribute property then we can have multiple logFilePlots ,plotting different data
        self.container = chaco.OverlayPlotContainer(padding=(120,20,20,40), bgcolor="white",
                                     use_backbuffer = True,
                                     border_visible = True,
                                     fill_padding = True)
        self.keyBindingsDictionary = {enable.KeySpec("F5"):self.refreshPlot,
                                      enable.KeySpec("F6"):self.forcefulRefresh,
                           enable.KeySpec("n","control"):self._add_lfp_wrapper,
                           enable.KeySpec("m","control"):self._add_with_current_lfp_wrapper,
                           enable.KeySpec("Delete"):self._deleteSelectedButton_fired,
                           enable.KeySpec("Delete","control"):self._deleteLogButton_fired }
        
          
    def parseSeries(self):
        """series is a column seperated string of all columns in log file 
        to be treated as a seperate series. If there are multiple values
        each unique combination is a new series"""
        if self.series=="":
            return []
        else:
            return self.series.split(",")
    
    def validateColumns(self):
        """not yet implemented """
        return None
        
    def _getMasterList(self):
        """gets the header row of log file which are interpreted as the column
        names that can be plotted."""
        logger.info("updating master list of axis choices")
        if not os.path.exists(self.logFile):
            return []
        try:
            with open(self.logFile) as csvfile:
                headerReader = csv.reader(csvfile)
                headerRow=headerReader.next()
            return headerRow
        except IOError:
            return []
            
    def _default_masterList(self):
        return self._getMasterList()
        
    def _xAxis_default(self):
        if "epoch seconds" in self.masterList:
            return "epoch seconds"
        else:
            self.masterList[0]
    
    def _yAxis_default(self):
        if "N" in self.masterList:
            return "N"
        else:
            self.masterList[0]
            
    def _logFile_changed(self):
        logger.debug("log file changed")
        self.masterList = self._getMasterList()
        self.checkIfLocalSettingsAvailable()
    
    def checkIfLocalSettingsAvailable(self):
        filename = os.path.join( os.path.split(self.logFile)[0], "logFilePlotSettings", "settings.json" )
        self.settingsAvailable = os.path.exists( filename )
    
    def _saveSettingsButton_fired(self):
        folder, _ = os.path.split(self.logFile)
        filename = os.path.join( folder, "logFilePlotSettings")
        if not os.path.exists( filename ):
            os.mkdir(filename)
        filename = os.path.join( filename, "settings.json" )
        settings = {}
        settingNames = [
            "mode",
            "errorBarMode",
            "groupValuesAccuracy",
            "xAxis",
            "yAxis",
            "seriesSelectedColumns",
            "series",
            "xLogScale",
            "yLogScale",
            "interpretAsTimeAxis"
        ]
        for sn in settingNames:
            settings[sn] = getattr(self,sn)
        with open(filename, 'w') as f:
            json.dump( settings, f )
        self.checkIfLocalSettingsAvailable()
    
    def _loadSettingsButton_fired(self):
        filename = os.path.join( os.path.split(self.logFile)[0], "logFilePlotSettings", "settings.json" )
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                settings = json.load( f )
            settingNames = [
            "mode",
            "errorBarMode",
            "groupValuesAccuracy",
            "xAxis",
            "yAxis",
            "seriesSelectedColumns",
            "series",
            "xLogScale",
            "yLogScale",
            "interpretAsTimeAxis"
        ]
        for sn in settingNames:
            if sn in settings:
                setattr(self,sn,settings[sn])
             
    def _interpretAsTimeAxis_changed(self):
        """flicks calendar scales on and off """
        if self.interpretAsTimeAxis:
            self.firstPlot.x_axis.tick_generator=ScalesTickGenerator(scale=CalendarScaleSystem())
            self.firstPlot.vgrid.tick_generator = self.firstPlot.x_axis.tick_generator
        else:
            self.firstPlot.x_axis.tick_generator=ScalesTickGenerator()
            self.firstPlot.vgrid.tick_generator = self.firstPlot.x_axis.tick_generator
        self.container.request_redraw()
            
        
    def getData(self):
        """using pandas, this function aggregates the data and groups by
        each series combination. Returns the aggregated data at which point 
        we can now see what we need to plot etc.

        All filters are performed after getting the dataframe but before returning
        the aggregate frame.
        """
        try:
            self.dataframe = pandas.read_csv(self.logFile, index_col="datetime", parse_dates = True, error_bad_lines=False, warn_bad_lines=True)
        except ValueError as e:
            logger.error("No datetime column. Is this a valid Eagle log file? I will try without index")
            self.dataframe = pandas.read_csv(self.logFile, parse_dates = True, error_bad_lines=False, warn_bad_lines=True)  
        self.filterData()
        seriesList = self.parseSeries()
        self.validateColumns()
        if self.mode == "X Variable - Measured Y":
            #The last column we aggregate over is the x axis. y axis gets mean and stdev per aggregation
            if self.groupSimilarValues:
                def groupFunc(x):
                    # rounds values to desired accuracy
                    return round(x,self.groupValuesAccuracy)
                dfRounded = self.dataframe.copy()
                columnsToGroup = seriesList+[self.xAxis]
                dfRounded[columnsToGroup] = dfRounded[columnsToGroup].applymap(groupFunc)
                return dfRounded.groupby( columnsToGroup, as_index=False).aggregate({self.yAxis:["mean","std","count"]})
            else:
                return self.dataframe.groupby(seriesList+[self.xAxis], as_index=False).aggregate({self.yAxis:["mean","std","count"]})
        elif self.mode == "X Measured - Y Measured":
            #here the x axis needs to be aggregated to mean and stdev as well as the y axis. aggregate axis defines the last axis we aggregate over
            #classic example here is a N vs T plot where aggregate axis is evaporation time. series would be for evaporation at different MT gradients
            return self.dataframe.groupby(seriesList+[self.aggregateAxis], as_index=False).aggregate({self.xAxis:["mean","std"],self.yAxis:["mean","std","count"]})
        elif self.mode == "XY Scatter":
            #here we don't care if x is a variable or measured. We just plot every x y point as a scatter point. no error bars.
            #here the raw data frame contains everything we need in the correct format!            
            return self.dataframe[seriesList+[self.xAxis,self.yAxis]]
        
    def humanSeriesName(self, seriesTuple):
        """returns the name for a given series Tuple"""
        name=""
        c=0
        for seriesName in self.seriesList:
            name+=seriesName+"="+str(seriesTuple[c])+" "
            c+=1
        name = name.strip(" ")
        return name
        
    def filterData(self):
        """filtering before aggregating the data for plots """
        if self.filterYs:
            self.performFilterYS()
        if self.filterXs:
            self.performFilterXS()
        if self.filterNaN:
            self.performFilterNaN()
        if self.filterSpecific:
            self.performFilterSpecific()
        
                
    def performFilterYS(self):
        """ remove y values above or below set bounds"""
        logger.debug("filtering y data before aggregating and plotting")
        logger.debug("dataframe was %s rows" % (len(self.dataframe)))
        self.dataframe = self.dataframe[(self.dataframe[self.yAxis]>self.filterMinYs) &(self.dataframe[self.yAxis]<self.filterMaxYs)]
        logger.debug("dataframe now %s rows" % (len(self.dataframe)))
        
    def performFilterXS(self):
        """remove x data above or below set bounds """
        logger.debug("filtering x data before aggregating and plotting")
        logger.debug("dataframe was %s rows" % (len(self.dataframe)))
        self.dataframe = self.dataframe[(self.dataframe[self.xAxis]>self.filterMinXs) &(self.dataframe[self.xAxis]<self.filterMaxXs)]
        logger.debug("dataframe now %s rows" % (len(self.dataframe)))
        
    def performFilterNaN(self):
        """removes NaN and replaces with zero """
        logger.debug("filtering NaN--> 0 in place")
        self.dataframe.fillna(value=0.0, inplace=True)

    def performFilterSpecific(self):
        """specific filter string is a comma separated list of filters. Supported filters are:
        ==, >, < and !="""
        filterStrings = self.filterSpecificString.split(",")
        for query in filterStrings:
            query = query.strip()
            if "==" in query:
                columnName, value = query.split("==")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]==value]
            elif ">" in query:
                columnName, value = query.split(">")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]>value]
            elif "<" in query:
                columnName, value = query.split("<")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]<value]
            elif "!=" in query:
                columnName, value = query.split("!=")
                columnName=columnName.strip()
                value=float(value.strip())
                self.dataframe = self.dataframe[self.dataframe[columnName]!=value]
            else:
                logger.error("unrecognised operator for query")
                
    def _filterVariableSelector_changed(self):
        """helper ui to stop user typing variable names wrong. """ 
        if self.filterSpecificString != "":
            self.filterSpecificString+=","
        self.filterSpecificString+=self.filterVariableSelector
        
   
    def getUniqueSeries(self, aggregatedDataFrame):
        """ given a aggregated data frame, this returns the list of all series
        names that are contained in the logFile."""
        self.seriesList = self.parseSeries()
        uniqueValues = [aggregatedDataFrame[seriesName].unique() for seriesName in self.seriesList] # [array(uniquevaluesseries1), array(uniquevaluesseries2),...]
        uniqueSeriesValues = list(itertools.product(*uniqueValues))#TODO at this point we should filter to only unique series combinations that actually have data
        #uniqueSeriesValuesWithData = []
        return uniqueSeriesValues
        
    def getRelevantData(self,aggregatedDataFrame,uniqueSeriesValueTuple):
        """given a uniqueSeriesValueTuple (e.g. (35, 0.002, 1) for (gradient, TOFtime, dummyVar)
        we return the aggregated data frame filtered to the relevant series.
        Returns None if there is no data in the relevant data frame this allows user to catch a non existing legend series        
        """
        relevantDataFrame = aggregatedDataFrame
        for columnName, value in zip(self.seriesList,uniqueSeriesValueTuple):
            logger.debug( "columnName, value = %s, %s" % (columnName, value) )
            logger.debug( "relevantDataFrame[relevantDataFrame[%s]==%s]" % (columnName, value) )
            relevantDataFrame = relevantDataFrame[relevantDataFrame[columnName]==value]
        logger.debug("relevantDataFrame = \n %s" % relevantDataFrame)
        if len(relevantDataFrame)==0:
            return None
        return relevantDataFrame
        
    def plotSetup(self):
        """ 
        called at the end of the plot function        
        add legend
        add x-y axis labels    
        """
        
        self.legend = chaco.Legend(component=self.container, padding=10, align="ur", font="modern 10")
        self.legend.tools.append(tools.LegendTool(self.legend, drag_button="right"))
        self.legend.plots = self.plots
        self.container.overlays.append(self.legend)
        self.legendTool = legendHighlighter.LegendHighlighter(self.legend, dim_factor=2.0, drag_button="right")
        self.legend.tools.append(self.legendTool)
        if self.mode == "XY Scatter":#add scatter selector tool
            for scatterPlot in self.container.plot_components:
                self.firstPlot.tools.append(scatterSelectorTool.ScatterSelector(scatterPlot, selection_mode="toggle",persistent_hover=False))
                self.firstPlot.overlays.append(chaco.ScatterInspectorOverlay(scatterPlot, hover_color = "transparent", hover_marker_size = 10, hover_outline_color = "purple",
                                    hover_line_width = 2,selection_marker_size = 8, selection_color = "lawngreen"))
                # Set up the trait handler for the selection
                scatterPlot.index.on_trait_change(self._metadata_handler_scatter_inspector, "metadata_changed")

    def clearAllPlots(self):
        """uses delplotmethod """
        logger.debug( "clearing %s " % self.plots.values())
        self.container.remove(*self.plots.values())
        self.container.remove(*self.errorPlots.values())
        self.container.tools.remove(self.keyBindingsTool)#maybe not necessary?
        if self.fitPlot is not None:
            try:
                self.container.remove(self.fitPlot)
            except Exception as e:
                logger.error("Attempted to remove a fit plot but couldn't... error = %s" % e.message)
            self.fitPlot = None
        self.container.overlays = []               
        self.plots={}
        self.errorPlots={}
        self.currentlyDefinedSeries = []
        self.firstPlot.overlays.remove(self.zoom)
        
        self.firstPlot = None
        self.container.invalidate_and_redraw()
        
    def _metadata_handler_scatter_inspector(self):
        """could remove this function in future as we don't really need it. see if it slows things down...."""
        for scatterPlot in self.container.plot_components:
            hover_indices = scatterPlot.index.metadata.get('hover', [])
            if hover_indices != []:
                x = scatterPlot.index.get_data()[hover_indices[0]]
                y = scatterPlot.value.get_data()[hover_indices[0]]
                if self.eagleReference is not None:
                    self.eagleReference.statusBarString = "(%G, %G)" % (x,y)
                elif self.logFilePlotsBool and (self.logFilePlotsReference is not None):
                    self.logFilePlotsReference.statusBarString = "(%G, %G)" % (x,y)#using log file plots so use this status bar
                return

    def refreshPlot(self):
        """clears current plot and then redraw it """
#        self.oldLegendPosition = [self.legend.x,self.legend.y]
        xsPrev = (self.firstPlot.x_axis.mapper.range.low,self.firstPlot.x_axis.mapper.range.high)
        ysPrev = (self.firstPlot.y_axis.mapper.range.low,self.firstPlot.y_axis.mapper.range.high)
        self.clearAllPlots()
        self.plot()
        if self.fitLogFileBool:
            logger.info("refreshing fit plot")
            self.setFittingData()
            if self.autoFitWithRefresh:
                self.logFilePlotFitterReference.fit()
            self.plotFit()
#        if self.oldLegendPosition is not None:
#            [self.legend.x,self.legend.y] = self.oldLegendPosition
        if self.softRefresh:
            self.firstPlot.x_axis.mapper.range.low = xsPrev[0]
            #self.firstPlot.x_axis.mapper.range.high = xsPrev[1]
            self.firstPlot.y_axis.mapper.range.low = ysPrev[0]
            self.firstPlot.y_axis.mapper.range.high = ysPrev[1]
            
        
    def plot(self):
        """Plots a line plot for each series and error bars if enough data exists
        depending on the state of the log file we might have a lot to plot 
        or not yet very much"""
        if self.mode == "X Variable - Measured Y":
            #The last column we aggregate over is the x axis. y axis gets mean and stdev per aggregation
            self.plotXVariable()
        elif self.mode == "X Measured - Y Measured":
            self.plotXMeasured()
        elif self.mode == "XY Scatter":
            self.plotXYScatter()
        self._interpretAsTimeAxis_changed()

    def initialiseFirstPlot(self, plot):
        self.firstPlot = plot
        chaco.add_default_grids(self.firstPlot)
        chaco.add_default_axes(self.firstPlot, vtitle = self.yAxis, htitle= self.xAxis)
        self.zoom = tools.ZoomTool(component=plot, tool_mode="box", always_on=True)
        #lets you define arbitrary key bindings for function calls
        self.keyBindingsTool = keyBindingsTool.KeyBindings(component=self.firstPlot,keyBindingsDictionary=self.keyBindingsDictionary)
        self.container.tools.append(self.keyBindingsTool)
        self.firstPlot.overlays.append(self.zoom)
        self.firstPlot.y_axis.tick_label_formatter = lambda val: ("%G"%val)
        self.firstPlot.x_axis.tick_label_formatter = lambda val: ("%G"%val)

    def plotXVariable(self):
        """plot function called when mode is set to "X variable - Measured Y"
        Plots a line plot for each series and error bars if enough data exists
        depending on the state of the log file we might have a lot to plot 
        or not yet very much"""
        aggregatedDataFrame = self.getData()
        if self.filterNaN:#here again if NaNs have occured in stdev
                logger.debug("filtering NaNs from relevantDataFrame")
                aggregatedDataFrame.fillna(value=0.0, inplace=True)
        logger.debug("aggregated data frame = \n %s" % aggregatedDataFrame)
        self.uniqueSeriesValues=self.getUniqueSeries(aggregatedDataFrame)
        c=0
        #we use the value and index mapper from the first plot for all plots
        for series in self.uniqueSeriesValues:
            logger.debug("now plotting series %s " % list(series))
            relevantDataFrame = self.getRelevantData(aggregatedDataFrame,series )
            if relevantDataFrame is None:#skip non existing legend series
                continue
            #get appropriate x data. Here x is a variable so we don't need mean
            xs = relevantDataFrame[self.xAxis].values
            #get appropriate y line (mean) data
            ys = relevantDataFrame[self.yAxis,"mean"].values
            #get appropriate y error bar data
            sigmasY = relevantDataFrame[self.yAxis,"std"].values
            if self.errorBarMode=='std err':
                sigmasY/=scipy.sqrt(relevantDataFrame[self.yAxis,"count"].values)
            errorsHigh = ys+sigmasY
            errorsLow = ys-sigmasY
            #create data sources:
            xsSource = chaco.ArrayDataSource(xs)
            ysSource = chaco.ArrayDataSource(ys)
            errorsHighSource = chaco.ArrayDataSource(errorsHigh)
            errorsLowSource = chaco.ArrayDataSource(errorsLow)
            #create line plot
            if c==0:
                #index range
                index_range = chaco.DataRange1D()
                index_range.add(xsSource)
                self.index_mapper = self.index_mapper_class(range=index_range)
                #value range
                value_range = chaco.DataRange1D()
                value_range.add(ysSource)
                self.value_mapper = self.value_mapper_class(range=value_range)
            else:
                self.value_mapper.range.add(ysSource)
                self.index_mapper.range.add(xsSource)
                
            plot = chaco.LinePlot(index=xsSource, value = ysSource,
                                  index_mapper = self.index_mapper, value_mapper = self.value_mapper,
                                  orientation="h", bgcolor="transparent", border_visible=False,
                                  color=tuple(RGBCONTRASTCOLORS[c % len(RGBCONTRASTCOLORS)]),line_width=2.0)            

            if c==0:
                self.initialiseFirstPlot(plot)
            #create errorbar plot
            errorPlotY = chaco.ErrorBarPlot(index=plot.index,index_mapper=plot.index_mapper,
                                           value_mapper=plot.value_mapper,
                                           value_high=errorsHighSource, value_low=errorsLowSource)
            self.container.add(plot)
            self.container.add(errorPlotY)
            seriesName = self.humanSeriesName(series)
            logger.debug("seriesName = %s " % seriesName)
            self.plots[seriesName]=plot
            self.errorPlots["Y-"+seriesName]=errorPlotY
            c+=1
        self.plotSetup()#adds tools etc
        
    def plotXMeasured(self):
        """plot function called when mode is set to "X measured - Measured Y"
        Plots a line plot for each series and error bars if enough data exists
        depending on the state of the log file we might have a lot to plot 
        or not yet very much"""
        aggregatedDataFrame = self.getData()
        if self.filterNaN:#here again if NaNs have occured in stdev
            logger.debug("filtering NaNs from relevantDataFrame")
            aggregatedDataFrame.fillna(value=0.0, inplace=True)
        logger.info("aggregated data frame = \n %s" % aggregatedDataFrame)
        self.uniqueSeriesValues=self.getUniqueSeries(aggregatedDataFrame)
        c=0
        #we use the value and index mapper from the first plot for all plots
        for series in self.uniqueSeriesValues:
            logger.debug("now plotting series %s " % list(series))
            relevantDataFrame = self.getRelevantData(aggregatedDataFrame,series )
            if relevantDataFrame is None:#skip non existing legend series
                continue
            #get appropriate x data. Here x is a variable so we don't need mean
            xs = relevantDataFrame[self.xAxis, "mean"].values
            #get appropriate y line (mean) data
            ys = relevantDataFrame[self.yAxis,"mean"].values
            #get appropriate y error bar data
            sigmasY = relevantDataFrame[self.yAxis,"std"].values
            if self.errorBarMode=='std err':
                sigmasY/=scipy.sqrt(relevantDataFrame[self.yAxis,"count"].values)
            errorsHigh = ys+sigmasY
            errorsLow = ys-sigmasY
            #create data sources:
            xsSource = chaco.ArrayDataSource(xs)
            ysSource = chaco.ArrayDataSource(ys)
            errorsHighSource = chaco.ArrayDataSource(errorsHigh)
            errorsLowSource = chaco.ArrayDataSource(errorsLow)
            #get appropriate x left right error bar data
            sigmasX = relevantDataFrame[self.xAxis,"std"].values
            if self.errorBarMode=='std err':
                sigmasX/=scipy.sqrt(relevantDataFrame[self.xAxis,"count"].values)
            errorsRight = xs+sigmasX
            errorsLeft = xs-sigmasX
            errorsRightSource = chaco.ArrayDataSource(errorsRight)
            errorsLeftSource = chaco.ArrayDataSource(errorsLeft)            
            #create line plot            
            if c==0:
                #index range
                index_range = chaco.DataRange1D()
                index_range.add(xsSource)
                self.index_mapper = self.index_mapper_class(range=index_range)
                #value range
                value_range = chaco.DataRange1D()
                value_range.add(ysSource)
                self.value_mapper = self.value_mapper_class(range=value_range)
            else:
                self.value_mapper.range.add(ysSource)
                self.index_mapper.range.add(xsSource)
                
            plot = chaco.LinePlot(index=xsSource, value = ysSource,
                                  index_mapper = self.index_mapper, value_mapper = self.value_mapper,
                                  orientation="h", bgcolor="transparent", border_visible=False,
                                  color=tuple(RGBCONTRASTCOLORS[c% len(RGBCONTRASTCOLORS)]),line_width=2.0)       
            #define value and index mapper once            
            if c==0:
                self.initialiseFirstPlot(plot)
            #create errorbar plot
            errorPlotY = chaco.ErrorBarPlot(index=plot.index,index_mapper=plot.index_mapper,
                                           value_mapper=plot.value_mapper, orientation="h",
                                           value_high=errorsHighSource, value_low=errorsLowSource)

            errorPlotX = chaco.ErrorBarPlot(index=plot.value,index_mapper=plot.value_mapper,
                                           value_mapper=plot.index_mapper, orientation="v",
                                           value_high=errorsRightSource, value_low=errorsLeftSource)
            self.container.add(plot)
            self.container.add(errorPlotY)
            self.container.add(errorPlotX)
            seriesName = self.humanSeriesName(series)
            logger.debug("seriesName = %s " % seriesName)
            self.plots[seriesName]=plot
            self.errorPlots["Y-"+seriesName]=errorPlotY
            self.errorPlots["X-"+seriesName]=errorPlotX
            c+=1
        self.plotSetup()#adds tools etc        

    def plotXYScatter(self):
        """ every x y point is a scatter point. We can still have different 
        series but no aggregation is performed."""
        """plot function called when mode is set to "X variable - Measured Y"
        Plots a line plot for each series and error bars if enough data exists
        depending on the state of the log file we might have a lot to plot 
        or not yet very much"""
        aggregatedDataFrame = self.getData()
        if self.filterNaN:#here again if NaNs have occured in stdev
            logger.debug("filtering NaNs from relevantDataFrame")
            aggregatedDataFrame.fillna(value=0.0, inplace=True)
        logger.info("aggregated data frame = \n %s" % aggregatedDataFrame)
        self.uniqueSeriesValues=self.getUniqueSeries(aggregatedDataFrame)
        c=0
        for series in self.uniqueSeriesValues:
            logger.debug("now plotting series %s " % list(series))
            relevantDataFrame = self.getRelevantData(aggregatedDataFrame,series )
            #get appropriate x data. Here x is a variable so we don't need mean
            if relevantDataFrame is None:#skip non existing legend series
                continue
            xs = relevantDataFrame[self.xAxis].values
            #get appropriate y line (mean) data
            ys = relevantDataFrame[self.yAxis].values
            xsSource = chaco.ArrayDataSource(xs)
            ysSource = chaco.ArrayDataSource(ys)
            #get appropriate y error bar data
            #create scatter plot
            if c==0:
                #index range
                index_range = chaco.DataRange1D()
                index_range.add(xsSource)                
                self.index_mapper = self.index_mapper_class(range=index_range)
                logger.warning("index mapper = %s " % self.index_mapper)
                #value range
                value_range = chaco.DataRange1D()
                value_range.add(ysSource)
                self.value_mapper = self.value_mapper_class(range=value_range)
            else:
                self.value_mapper.range.add(ysSource)
                self.index_mapper.range.add(xsSource)
            plot = chaco.ScatterPlot(index=xsSource, value=ysSource,
                         index_mapper=self.index_mapper,value_mapper=self.value_mapper,
                         orientation="h", marker="circle",marker_size=6.0,color=tuple(RGBCONTRASTCOLORS[c% len(RGBCONTRASTCOLORS)]),
                         bgcolor="transparent", outline_color="black",  border_visible=True,)
            #define value and index mapper once            
            if c==0:
                self.initialiseFirstPlot(plot)
            else:
                #extend ranges where appropriate
                plot.value_mapper = self.value_mapper
                self.value_mapper.range.add(plot.value)
                plot.index_mapper = self.index_mapper
                self.index_mapper.range.add(plot.index)
            self.container.add(plot)
            seriesName = self.humanSeriesName(series)
            logger.debug("seriesName = %s " % seriesName)
            self.plots[seriesName]=plot
            c+=1
        self.plotSetup()#adds tools etc
        
    def _logFilePlotBool_changed(self):
        if self.logFilePlotBool:
            self.plot()
        elif not self.logFilePlotBool:
            self.clearAllPlots()
        #force a refresh of the column names. sometimes if we delete a log and add columns this useful otherwise user had to change file and change back to see new columns
        self.masterList = self._getMasterList()

    def forcefulRefresh(self):
        if self.logFilePlotBool:
            self.clearAllPlots()
        self.plot()
        self.masterList = self._getMasterList()
        if not self.logFilePlotBool:
            self.logFilePlotBool = True
        
    def _yLogScale_changed(self):
        """changes value mapper class and then refreshes plot """
        if self.yLogScale:
            self.value_mapper_class = chaco.LogMapper
            self.refreshPlot()
            logger.debug( "switching to y axis log scale")
            self.firstPlot.y_axis.tick_label_formatter = lambda val: ("%.2E"%val)
            self.firstPlot.y_axis.tick_generator = chaco.ticks.log_auto_ticks
        else:
            logger.debug( "switching to y axis linear scale")
            self.value_mapper_class = chaco.LinearMapper
            self.refreshPlot()
            self.firstPlot.y_axis.tick_label_formatter = lambda val: ("%G"%val)
            
    def _xLogScale_changed(self):
        """changes index mapper class and then refreshes plot """
        if self.xLogScale:
            self.index_mapper_class = chaco.LogMapper
            
            self.refreshPlot()
            logger.debug( "switching to x axis log scale")
            self.firstPlot.x_axis.tick_label_formatter = lambda val: ("%.2E"%val)
        else:
            logger.debug( "switching to x axis linear scale")
            self.index_mapper_class = chaco.LinearMapper
            self.refreshPlot()
            self.firstPlot.x_axis.tick_label_formatter = lambda val: ("%G"%val)

    def _refreshButton_fired(self):
        self.refreshPlot()
                
    def savePlotAsImageDialog(self):
        """save plots as image uses the matplotlib engine and matplotlibify
        sub library to create publication quality plots and automatically save them to oneNote"""
        import matplotlibify.matplotlibify
        
        dialog = matplotlibify.matplotlibify.Matplotlibify(logFilePlotReference =self,logFilePlotsReference=self.logFilePlotsReference )
        dialog.templatesFolder = os.path.join("\\\\ursa","AQOGroupFolder","Experiment Humphry","Experiment Control And Software","LogFilePlots","matplotlibify","templates")
        dialog.templateFile = os.path.join(dialog.templatesFolder,"matplotlibifyDefaultTemplate.py")
        dialog.configure_traits()
        
    def savePlotAsImage(self, matplotlibifyObject,librarianObject=None, name=None, oneNote=True):
        if name is None:#use automatic location
            logFolder,tail = os.path.split(self.logFile)
            #logName = tail.replace(".csv","")+" - "+str(self.xAxis)+" vs "+str(self.yAxis)
            logName =str(self.xAxis)+" vs "+str(self.yAxis)
            filename = datetime.datetime.today().strftime("%Y-%m-%dT%H%M%S")+"-"+logName+".png"
            imageFileName =os.path.join(logFolder, filename)
        else:
            imageFileName = name
        logger.info("saving image: %s" % imageFileName)
        matplotlibifyObject.autoSavePlotWithMatplotlib(imageFileName)
        logger.info("saved image as file")

        if ONENOTE_ENABLED and oneNote:
            if librarianObject is None:
                ONENOTE_NotebookName = "Humphry's Notebook"
                ONENOTE_SectionName = "Eagle Logs"
            else:
                ONENOTE_NotebookName = librarianObject.notebookName
                ONENOTE_SectionName = librarianObject.sectionName
            try:
                logger.info("attempting to save image to oneNote page")
                logName = tail.replace(".csv","")#this is what the name of the page should be in oneNote
                eagleOneNote = oneNotePython.eagleLogsOneNote.EagleLogOneNote(notebookName =ONENOTE_NotebookName, sectionName = ONENOTE_SectionName)
                logPage = eagleOneNote.setPage(logName)
                if logPage is None:
                    logger.info("saving image to one note . page doesn't exist. creating page")
                    eagleOneNote.createNewEagleLogPage(logName, refresh=True, setCurrent=True)
                logger.debug("attempting to save image")
                eagleOneNote.addImageToPlotOutline(imageFileName, (6.3*300,3.87*300),rewrite=True)
                if self.fitLogFileBool and self.fitPlot is not None and self.logFilePlotFitterReference.isFitted:
                    #these conditions mean that we have the fit data we can write to one note with the image!
                    logger.info("also writing fit data to one note")
                    eagleOneNote.setOutline("plots", eagleOneNote.getOutlineText("plots")+self.logFilePlotFitterReference.modelFitResult.fit_report())
                eagleOneNote.currentPage.rewritePage()
                #now to get resizing done well we want to completely repull the XML and data
                #brute force method:
                eagleOneNote = oneNotePython.eagleLogsOneNote.EagleLogOneNote(notebookName =ONENOTE_NotebookName, sectionName = ONENOTE_SectionName)
                logPage = eagleOneNote.setPage(logName)
                eagleOneNote.organiseOutlineSizes()
            
            except Exception as e:
                logger.error("failed to save the image to OneNote. error: %s " % e.message)
    
    def _savePlotButton_fired(self):
        """call default save image function when button is fired """
        self.savePlotAsImageDialog()#default location as no name argument passed
        
    def _autoSavePlot(self):
        """saves plot to a default location for the autosave plot location.
        This means users with remote access to a certain folder can see the progress
        of a plot by looking at the file or by using the lab email daemon service 
        (available for Experiment Humphry)"""
        defaultLocation = os.path.join("N:", os.sep, "Data", "eagleLogs", "autoSaveEagleLogFilePlot.png")
        import matplotlibify.matplotlibify
        self.savePlotAsImage(matplotlibify.matplotlibify.Matplotlibify(logFilePlotReference =self,logFilePlotsReference=self.logFilePlotsReference ),name=defaultLocation, oneNote=False)
    
    def autoRefresh(self):
        """this is what the auto refresh timer calls . 
        it calls the refresh function and the autoSavePlot function"""
        logger.info("auto refresh function called")
        #check whether we need autorefresh alert checks and execute before refresh (i.e. before any filters etc.)
        if (self.autoRefreshObject is not None) and (self.autoRefreshObject.emailAlertBool or self.autoRefreshObject.soundAlertBool):
            try:
                logger.info("attempting autorefresh alert code execution")
                exec(self.autoRefreshObject.alertCode)#defines a function called alertAnalyser(dataFrameTail)
                alertBool = alertAnalyser(self.dataframe.tail(self.autoRefreshObject.linesOfDataFrame))
                logger.debug("dataframe tailed = %s" % self.dataframe.tail(self.autoRefreshObject.linesOfDataFrame))
                logger.info("alert Bool returned %s" % alertBool)
                if alertBool:
                    if self.autoRefreshObject.emailAlertBool:
                        import labAlerts
                        labAlerts.writeAlert("High","Eagle Autorefresh","alert code fired","(For Tim:\n\n%s" % self.autoRefreshObject.alertCode,waitTime=10.0 )
                    if self.autoRefreshObject.soundAlertBool:
                        import labSounds
                        ss=labSounds.getSoundSystem()
                        ss.againstMyWishes(1)
            except Exception as e:
                logger.error("failed to run alert analyser. error message %s " % e.message)

        self._refreshButton_fired()

        if (self.autoRefreshObject is not None):
            if self.autoRefreshObject.autoSaveBool:
                try:
                    self._autoSavePlot()
                except Exception as e:
                    logger.error("failed to autosave plot. error message %s " % e.message)

    
    def _librarianButton_fired(self):
        librarian = oneNotePython.logLibrarianOneNote.Librarian(logFolder = os.path.split(self.logFile)[0], xAxis = self.xAxis, 
                                                                yAxis = self.yAxis,logFilePlotReference =self,logFilePlotsReference=self.logFilePlotsReference)
        librarian.edit_traits()

    def _seriesEdit_fired(self):
        selected = self.columnSelectorDialog()
        self.series = ",".join(selected)
        logger.info("content of selected columns = %s " % self.seriesSelectedColumns)

    def _deleteLogButton_fired(self):
        """removes log folder and all its contents """
        logger.warning("about to attempt to delete a log folder and all its contents")
        logFolder,tail = os.path.split(self.logFile )
        parent,logFolderName = os.path.split(logFolder)
        confirmation = traitsui.error(message="Warning: This will permanently delete the selected log folder and all its contents:\n%s\n. Do you wish to proceed?" % logFolder)
        if confirmation:
            logger.info("beginning delete checks")
            
            if os.path.split(parent)[1] != "eagleLogs":
                logger.error("cannot delete a log that is not inside Eagle logs for safety...This log was in %s" % os.path.split(parent)[1])
                return
            logName = tail.replace(".csv","")
            logger.warning("DELETING FOLDER %s " % logFolder)
            shutil.rmtree(logFolder)
            logger.warning("Folder %s deleted " % logFolder)
        else:
            logger.info("user cancelled deleting request")
            
            
    def _deleteSelectedButton_fired(self):
        """removes points selected in the scatter mode from the CSV file itself. 
        they will then be gone when  user clicks refresh"""
        confirmation = traitsui.error(message="Warning: This will permanently delete the selected points from the log file.\n If you are applying filters, filtered points will be deleted too.\n\n. Do you wish to proceed?")
        if not confirmation:
            return
        if self.mode != "XY Scatter":#NOTE HORRIBLE BUGS / issues could occur if user changes to scatter mode without clicking refresh..... etc.
            logger.error("this function should only be called when mode is XY scatter")
            return
        dataToDelete = []#will be a list of tuples of (x,y) data
        for scatterPlot in self.container.plot_components:
            sel_indices = scatterPlot.index.metadata.get('selections', [])
            if sel_indices != []:#some points in this scatter plot have been selected
                print sel_indices
                dataToDelete+=[(scatterPlot.index.get_data()[index], scatterPlot.value.get_data()[index]) for index in sel_indices] 
        logger.info("data to delete list = %s" % dataToDelete)
        
        if dataToDelete == []:
            logger.error("error while deleting selected. Found no selected points")
            return
        #now we do the finding and deleting....
        try:
            dataframe = pandas.read_csv(self.logFile, index_col="datetime", parse_dates = True, error_bad_lines=False, warn_bad_lines=True)
        except ValueError as e:
            logger.error("No datetime column. Is this a valid Eagle log file? I will try without index")
            dataframe = pandas.read_csv(self.logFile, parse_dates = True, error_bad_lines=False, warn_bad_lines=True)
        #make backup of original file before deleting        
        shutil.copyfile(self.logFile, self.logFile+".backup")
        #FILTER AS PER SETTINGS IN EAGLE
        if self.filterYs:
            dataframe = dataframe[(dataframe[self.yAxis]>self.filterMinYs) &(dataframe[self.yAxis]<self.filterMaxYs)]
        if self.filterXs:
            dataframe = dataframe[(dataframe[self.xAxis]>self.filterMinXs) &(dataframe[self.xAxis]<self.filterMaxXs)]
        dataframe.fillna(value=0.0, inplace=True)
        
        for deleteX,deleteY in dataToDelete:
            dataframe =dataframe[(dataframe[self.xAxis]!=deleteX) | (dataframe[self.yAxis]!=deleteY)]
        dataframe.to_csv(self.logFile)
        self.refreshPlot()#refresh plot so user gets to instantly see removal

    def columnSelectorDialog(self):
        """pulls up a check list editor dialog to choose columns in log file series
        Changes the value of seriesSelectedColumns """
        self.masterList = self._getMasterList()
        
        checklist_group = traitsui.Group('10', # insert vertical space
                                        traitsui.Label('Select the series to group plots by:'),
                                        traitsui.UItem( 'seriesSelectedColumns', style = 'custom',editor = traitsui.CheckListEditor(values =self._getMasterList(), cols   = 6 )))
        traits_view = traitsui.View(
                                    checklist_group,
                                    title     = 'Column Selector',
                                    buttons   = [ 'OK' ],
                                    resizable = True,
                                    kind='livemodal'
                                    )
                                    
        self.edit_traits(view=traits_view)
        logger.info("content of selected columns = %s " % self.seriesSelectedColumns)
        return self.seriesSelectedColumns

    def setFittingData(self):
        """gets a list of all valid series aggregated
        then iterates through and sends them to fitting module"""
        logger.info("beginning set Fitting Data func")
        aggregatedDataFrame = self.getData()
        uniqueSeriesValueTuples = self.getUniqueSeries(aggregatedDataFrame)
        logger.warning("uniqueSeriesValuesTuples=%s", uniqueSeriesValueTuples)
        validNames = []#can change when user presses refresh
        for uniqueSeriesValueTuple in uniqueSeriesValueTuples:#TODO ADD SORTED STATEMENT  
            relevantDataFrame=self.getRelevantData(aggregatedDataFrame,uniqueSeriesValueTuple)
            if relevantDataFrame is None:#skip non existing legend series
                continue
            xs = relevantDataFrame[self.xAxis].values
            if self.mode == "XY Scatter":
                ys = relevantDataFrame[self.yAxis].values
            else:
                ys = relevantDataFrame[self.yAxis,"mean"].values
            humanName = self.humanSeriesName(uniqueSeriesValueTuple)
            if humanName == "":
                humanName="data"
            self.logFilePlotFitterReference.setFitData(humanName,xs,ys)
            validNames.append(humanName) 
        self.logFilePlotFitterReference.cleanValidNames(validNames)#removes unecessary elements from datasets dict
        self.logFilePlotFitterReference.setValidNames()#resets name choices to only be remaining valid keys of datasets dict
        
    def plotFit(self):
        """plots current fit"""
        if not self.logFilePlotFitterReference.isFitted:
            logger.info("cannot plot a fit that hasn't been fitted")
            return 
        if self.fitPlot is not None:
            self.container.remove(self.fitPlot)
        dataX, dataY = self.logFilePlotFitterReference.getFitData()
        self.fitXS = chaco.ArrayDataSource(dataX)
        self.fitYS = chaco.ArrayDataSource(dataY)
        self.fitPlot=chaco.LinePlot(index=self.fitXS, value = self.fitYS,
                                  index_mapper = self.index_mapper, value_mapper = self.value_mapper,
                                  orientation="h", bgcolor="transparent", border_visible=False,
                                  color="black",line_width=4.0)   
        #plot.value_mapper = self.value_mapper
        self.container.add(self.fitPlot)
        #self.fitPlot.x_axis = self.firstPlot.x_axis
        #self.fitPlot.y_axis = self.firstPlot.y_axis
        self.value_mapper.range.add(self.fitPlot.value)
        #plot.index_mapper = self.index_mapper
        self.index_mapper.range.add(self.fitPlot.index)
        
        self.container._request_redraw()
        
    def _fitLogFileBool_changed(self):
        """load data to LogFilePlotFitter when fitting view is visible """
        if self.fitLogFileBool:
            self.setFittingData()
            
    def _add_lfp_wrapper(self):
        """wrapper function that can be used for when you have logFilePLots enabled """
        return self.logFilePlotsReference._add_lfp()
    
    def _add_with_current_lfp_wrapper(self):
        """wrapper function that can be used for when you have logFilePLots enabled """
        return self.logFilePlotsReference._add_with_current_lfp()
        
    def load_parse(self, value, typeString):
        if 'str' in typeString:
            return str(value)
        if 'unicode' in typeString:
            return unicode(value)
        elif 'float' in typeString:
            return scipy.float_(value)
        elif 'bool' in typeString:
            if value=='True':
                return True
            else:
                return False
        elif 'List' in typeString or 'list' in typeString:
            return eval(value)
            
    def load_settings(self, savedDictionary):
        """load the values from the dictionary:
        loads: 'mode','logFilePlotBool','fitLogFileBool','autoFitWithRefresh','softRefresh',
                        'errorBarMode','logFile','xAxis' ,'yAxis','aggregateAxis','masterList','series',
                        'xLogScale','yLogScale','interpretAsTimeAxis','filterYs','filterMinYs','filterMaxYs',
                        'filterXs','filterMinXs','filterMaxXs','filterNaN','filterSpecific','filterSpecificString',
                        'filterVariableSelector','logFilePlotsBool','logFilePlotsTabName'"""
        logger.info("loading settings for lfp: %s " % savedDictionary)
        
        special_cases = []        
        
        vars_for_loading = ['mode','fitLogFileBool','autoFitWithRefresh','softRefresh',
                        'errorBarMode','logFile','xAxis', 'yAxis','aggregateAxis','masterList','series',
                        'xLogScale','yLogScale','interpretAsTimeAxis','filterYs','filterMinYs','filterMaxYs',
                        'filterXs','filterMinXs','filterMaxXs','filterNaN','filterSpecific','filterSpecificString',
                        'filterVariableSelector','logFilePlotsTabName','logFilePlotBool']
        
        for variable in vars_for_loading:
            (value,typeString) = savedDictionary[variable]
            setattr(self, variable, self.load_parse(value,typeString))
            del savedDictionary[variable]
        #any missing items end up in this loop                
        for (variable, (value,typeString)) in savedDictionary.iteritems():
            if variable in special_cases:
                continue
            else:
                setattr(self, variable, self.load_parse(value,typeString))
        
if __name__=="__main__":
    lfp = LogFilePlot()
    lfp.configure_traits()
